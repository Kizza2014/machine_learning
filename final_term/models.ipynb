{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a757d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC, ADASYN\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d358104",
   "metadata": {},
   "source": [
    "Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b221cb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartDiseaseorAttack  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   Diabetes  PhysActivity  Fruits  ...  AnyHealthcare  NoDocbcCost  GenHlth  \\\n",
       "0       0.0           0.0     0.0  ...            1.0          0.0      5.0   \n",
       "1       0.0           1.0     0.0  ...            0.0          1.0      3.0   \n",
       "2       0.0           0.0     1.0  ...            1.0          1.0      5.0   \n",
       "3       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "4       0.0           1.0     1.0  ...            1.0          0.0      2.0   \n",
       "\n",
       "   MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
       "0      18.0      15.0       1.0  0.0   9.0        4.0     3.0  \n",
       "1       0.0       0.0       0.0  0.0   7.0        6.0     1.0  \n",
       "2      30.0      30.0       1.0  0.0   9.0        4.0     8.0  \n",
       "3       0.0       0.0       0.0  0.0  11.0        3.0     6.0  \n",
       "4       3.0       0.0       0.0  0.0  11.0        5.0     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/heart_disease_health_indicators_BRFSS2015.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471eb96d",
   "metadata": {},
   "source": [
    "Train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a23b23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202944, 21) (50736, 21)\n",
      "(202944,) (50736,)\n"
     ]
    }
   ],
   "source": [
    "X, y = data.drop('HeartDiseaseorAttack', axis=1), data['HeartDiseaseorAttack']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42, stratify=y)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded54c6",
   "metadata": {},
   "source": [
    "## 1. Dealing with imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69684e98",
   "metadata": {},
   "source": [
    "#### 1.1. Oversampling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac564f3a",
   "metadata": {},
   "source": [
    "a. Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eb069da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_data = X_train.copy()\n",
    "imbalanced_data['HeartDiseaseorAttack'] = y_train.copy()\n",
    "\n",
    "minority_class = imbalanced_data[imbalanced_data['HeartDiseaseorAttack'] == 1.0]\n",
    "majority_class = imbalanced_data[imbalanced_data['HeartDiseaseorAttack'] == 0.0]\n",
    "\n",
    "# upsample the minority class\n",
    "minority_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "\n",
    "# combine the upsampled minority class with the majority class\n",
    "balanced_data = pd.concat([majority_class, minority_upsampled])\n",
    "X_train_ro, y_train_ro = balanced_data.drop('HeartDiseaseorAttack', axis=1), balanced_data['HeartDiseaseorAttack']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dab7d1",
   "metadata": {},
   "source": [
    "b. SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "31a22013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote treat all features as numerical\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5f74f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smotenc for numerical and categorical features\n",
    "smotenc = SMOTENC(random_state=42, categorical_features=['GenHlth', 'Age', 'Education','Income'])\n",
    "X_train_smotenc, y_train_smotenc = smotenc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1fe86",
   "metadata": {},
   "source": [
    "c. ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01d944d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24816909",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7ec9c",
   "metadata": {},
   "source": [
    "#### 2.1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb4b64",
   "metadata": {},
   "source": [
    "Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e80f96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95     45957\n",
      "         1.0       0.44      0.05      0.09      4779\n",
      "\n",
      "    accuracy                           0.90     50736\n",
      "   macro avg       0.68      0.52      0.52     50736\n",
      "weighted avg       0.87      0.90      0.87     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "k = int(math.sqrt(X_train_scaled.shape[0]))\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ef2baa",
   "metadata": {},
   "source": [
    "Neighborhood Components Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa619ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 38.4 GiB for an array with shape (202944, 202944) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39msqrt(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m      2\u001b[0m nca \u001b[38;5;241m=\u001b[39m NeighborhoodComponentsAnalysis(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X_train_nca \u001b[38;5;241m=\u001b[39m \u001b[43mnca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m X_test_nca \u001b[38;5;241m=\u001b[39m nca\u001b[38;5;241m.\u001b[39mtransform(X_test_pca)\n\u001b[0;32m      7\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mk, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:921\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_nca.py:300\u001b[0m, in \u001b[0;36mNeighborhoodComponentsAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    297\u001b[0m t_train \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# Compute a mask that stays fixed during optimization:\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m same_class_mask \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# (n_samples, n_samples)\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# Initialize the transformation\u001b[39;00m\n\u001b[0;32m    304\u001b[0m transformation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize(X, y, init))\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 38.4 GiB for an array with shape (202944, 202944) and data type bool"
     ]
    }
   ],
   "source": [
    "k = int(math.sqrt(X_train.shape[0]))\n",
    "nca = NeighborhoodComponentsAnalysis(init='pca')\n",
    "\n",
    "X_train_nca = nca.fit_transform(X_train_pca, y_train)\n",
    "X_test_nca = nca.transform(X_test_pca)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(X_train_nca, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_nca)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29df6c",
   "metadata": {},
   "source": [
    "Random oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734502fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     45957\n",
      "         1.0       0.23      0.79      0.36      4779\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.60      0.76      0.59     50736\n",
      "weighted avg       0.90      0.73      0.79     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_ro_scaled = std_scaler.fit_transform(X_train_ro)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "k = int(math.sqrt(X_train_ro.shape[0]))\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(X_train_ro_scaled, y_train_ro)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44861333",
   "metadata": {},
   "source": [
    "SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d90864d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.74      0.84     45957\n",
      "         1.0       0.23      0.77      0.36      4779\n",
      "\n",
      "    accuracy                           0.74     50736\n",
      "   macro avg       0.60      0.75      0.60     50736\n",
      "weighted avg       0.90      0.74      0.79     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_smote_scaled = std_scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "k = int(math.sqrt(X_train_smote.shape[0]))\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(X_train_smote_scaled, y_train_smote)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7409c0",
   "metadata": {},
   "source": [
    "SMOTENC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a2129d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     45957\n",
      "         1.0       0.23      0.77      0.35      4779\n",
      "\n",
      "    accuracy                           0.74     50736\n",
      "   macro avg       0.60      0.75      0.59     50736\n",
      "weighted avg       0.90      0.74      0.79     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_smotenc_scaled = std_scaler.fit_transform(X_train_smotenc)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "k = int(math.sqrt(X_train_smotenc.shape[0]))\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(X_train_smotenc_scaled, y_train_smotenc)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab3246",
   "metadata": {},
   "source": [
    "ADASYN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "709e3596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.73      0.83     45957\n",
      "         1.0       0.23      0.78      0.35      4779\n",
      "\n",
      "    accuracy                           0.73     50736\n",
      "   macro avg       0.60      0.75      0.59     50736\n",
      "weighted avg       0.90      0.73      0.79     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_adasyn_scaled = std_scaler.fit_transform(X_train_adasyn)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "k = int(math.sqrt(X_train_adasyn.shape[0]))\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "knn.fit(X_train_adasyn_scaled, y_train_adasyn)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0509b",
   "metadata": {},
   "source": [
    "#### 2.2. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479bc3f",
   "metadata": {},
   "source": [
    "##### a. Without resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "15dae7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.85     45957\n",
      "         1.0       0.25      0.80      0.38      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced')\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abda7eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.74      0.84     45957\n",
      "         1.0       0.24      0.80      0.37      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log_loss', class_weight='balanced')\n",
    "sgd_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea5f9a",
   "metadata": {},
   "source": [
    "##### b. Using resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f52327",
   "metadata": {},
   "source": [
    "Random oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8885162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.85     45957\n",
      "         1.0       0.25      0.80      0.38      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_ro_scaled = std_scaler.fit_transform(X_train_ro)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_ro_scaled, y_train_ro)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47448181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.85     45957\n",
      "         1.0       0.25      0.80      0.38      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_ro_scaled = std_scaler.fit_transform(X_train_ro)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log_loss')\n",
    "sgd_clf.fit(X_train_ro_scaled, y_train_ro)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89155b",
   "metadata": {},
   "source": [
    "SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3114d19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.75      0.85     45957\n",
      "         1.0       0.25      0.78      0.38      4779\n",
      "\n",
      "    accuracy                           0.76     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.76      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_smote_scaled = std_scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_smote_scaled, y_train_smote)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "83723b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.77      0.86     45957\n",
      "         1.0       0.26      0.77      0.38      4779\n",
      "\n",
      "    accuracy                           0.77     50736\n",
      "   macro avg       0.61      0.77      0.62     50736\n",
      "weighted avg       0.90      0.77      0.81     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_smote_scaled = std_scaler.fit_transform(X_train_smote)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log_loss')\n",
    "sgd_clf.fit(X_train_smote_scaled, y_train_smote)\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194fb41d",
   "metadata": {},
   "source": [
    "ADASYN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8f48072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.74      0.84     45957\n",
      "         1.0       0.24      0.80      0.37      4779\n",
      "\n",
      "    accuracy                           0.75     50736\n",
      "   macro avg       0.61      0.77      0.61     50736\n",
      "weighted avg       0.90      0.75      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_adasyn_scaled = std_scaler.fit_transform(X_train_adasyn)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_adasyn_scaled, y_train_adasyn)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "X_train_adasyn_scaled = std_scaler.fit_transform(X_train_adasyn)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "sgd_clf = SGDClassifier(loss='log_loss')\n",
    "log_reg.fit(X_train_adasyn_scaled, y_train_adasyn)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
